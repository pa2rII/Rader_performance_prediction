{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvqxNf5QjCaI0aLtE59Q9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssumannb/Rader_performance_prediction/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8oWeb136t0E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.linear_model import LassoCV , ElasticNetCV , RidgeCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
        "from sklearn.ensemble import RandomForestRegressor as RFR\n",
        "from sklearn.cross_decomposition import PLSRegression as  PLS\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(42) # Seed 고정\n",
        "\n",
        "PATH = \"./data\"\n",
        "\n",
        "train_df = pd.read_csv(f'{PATH}/train.csv')\n",
        "train_x = train_df.filter(regex='X') # Input : X Featrue\n",
        "train_y = train_df.filter(regex='Y') # Output : Y Feature\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2)\n",
        "\n",
        "# for col in train_x:\n",
        "#   print(col,len(train_x[col].unique()))\n",
        "\n",
        "\n",
        "cv = ShuffleSplit(n_splits=5 , test_size=0.3, random_state=42)\n",
        "pipe_linear = Pipeline([('scl', StandardScaler()),\n",
        "                        ('poly', PolynomialFeatures()),\n",
        "                        ('fit', LinearRegression())])\n",
        "pipe_lasso = Pipeline([('scl', StandardScaler()),\n",
        "                       ('poly', PolynomialFeatures()),\n",
        "                       ('fit', Lasso(random_state = 42))])\n",
        "pipe_ridge = Pipeline([('scl', StandardScaler()),\n",
        "                       ('poly', PolynomialFeatures()),\n",
        "                       ('fit', Ridge(random_state = 42))])\n",
        "pipe_pca = Pipeline([('scl', StandardScaler()),\n",
        "                     ('pca', PCA()),\n",
        "                     ('fit', Ridge(random_state = 42))])\n",
        "pipe_pls = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', PLS())])\n",
        "pipe_gbr = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', GBR())])\n",
        "pipe_rfr = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', RFR())])\n",
        "pipe_svr = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', SVR())])\n",
        "pipe_KR = Pipeline([('scl', StandardScaler()),\n",
        "                    ('fit', KernelRidge())])\n",
        "pipes = [\n",
        "    pipe_linear , pipe_lasso ,  pipe_pca ,\n",
        "    pipe_ridge , pipe_pls , pipe_gbr ,\n",
        "    pipe_rfr , pipe_svr , pipe_KR\n",
        "]\n",
        "pipes_label = [\n",
        "    'linear', 'lasso', 'pca', 'ridge',\n",
        "    'pls', 'gbr', 'rfr', 'svr', 'KR'\n",
        "]\n",
        "\n",
        "grid_params_linear = [{\n",
        "    \"poly__degree\" : np.arange(1,3),\n",
        "    \"fit__fit_intercept\" : [True, False],\n",
        "}]\n",
        "grid_params_lasso = [{\n",
        "    \"poly__degree\" : np.arange(1,3),\n",
        "    \"fit__tol\" : np.logspace(-5,0,10) ,\n",
        "    \"fit__alpha\" : np.logspace(-5,1,10) ,\n",
        "                     }]\n",
        "grid_params_pca = [{\n",
        "    \"pca__n_components\" : np.arange(2,8)\n",
        "}]\n",
        "grid_params_ridge = [{\n",
        "    \"poly__degree\" : np.arange(1,3),\n",
        "    \"fit__alpha\" : np.linspace(2,5,10) ,\n",
        "    \"fit__solver\" : [ \"cholesky\",\"lsqr\",\"sparse_cg\"] ,\n",
        "    \"fit__tol\" : np.logspace(-5,0,10) ,\n",
        "                     }]\n",
        "grid_params_pls = [{\n",
        "    \"fit__n_components\" : np.arange(2,8)\n",
        "}]\n",
        "min_samples_split_range = [0.5, 0.7 , 0.9]\n",
        "\n",
        "grid_params_gbr =[{\n",
        "    \"fit__max_features\" : [\"sqrt\",\"log2\"] ,\n",
        "    \"fit__loss\" : [\"ls\",\"lad\",\"huber\",\"quantile\"] ,\n",
        "    \"fit__max_depth\" : [5,6,7,8] ,\n",
        "    \"fit__min_samples_split\" : min_samples_split_range ,\n",
        "}]\n",
        "grid_params_rfr =[{\n",
        "    \"fit__max_features\" : [\"sqrt\",\"log2\"] ,\n",
        "    \"fit__max_depth\" : [5,6,7,8] ,\n",
        "    \"fit__min_samples_split\" : min_samples_split_range ,\n",
        "}]\n",
        "grid_params_svr =[{\n",
        "    \"fit__kernel\" : [\"rbf\", \"linear\"] ,\n",
        "    \"fit__degree\" : [2, 3, 5] ,\n",
        "    \"fit__gamma\" : np.logspace(-5,1,10) ,\n",
        "}]\n",
        "grid_params_KR =[{\n",
        "    \"fit__kernel\" : [\"rbf\",\"linear\"] ,\n",
        "    \"fit__gamma\" : np.logspace(-5,1,10) ,\n",
        "}]\n",
        "params = [\n",
        "    grid_params_linear , grid_params_lasso , grid_params_pca,\n",
        "    grid_params_ridge , grid_params_pls , grid_params_gbr ,\n",
        "    grid_params_rfr , grid_params_svr , grid_params_KR\n",
        "]\n",
        "\n",
        "pipes_dict = {}\n",
        "for pipe, label in zip(pipes, pipes_label):\n",
        "    _pipes = []\n",
        "    for _ in range(14):\n",
        "        _pipes.append(pipe)\n",
        "\n",
        "    pipes_dict[label] = _pipes\n",
        "\n",
        "def lg_nrmse(gt, preds):\n",
        "    # 각 Y Feature별 NRMSE 총합\n",
        "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
        "    all_nrmse = []\n",
        "    for idx in range(14): # ignore 'ID'\n",
        "        rmse = metrics.mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
        "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
        "        all_nrmse.append(nrmse)\n",
        "    score = 1.2 * np.sum(all_nrmse[:7]) + 1.0 * np.sum(all_nrmse[7:13])\n",
        "    return score\n",
        "\n",
        "\n",
        "scores_dict = {}\n",
        "preds_dict = {}\n",
        "test_pred = {}\n",
        "test_x = pd.read_csv(f'{PATH}/test.csv').drop(columns=['ID'])\n",
        "\n",
        "cv = ShuffleSplit(n_splits=5 , test_size=0.3, random_state=42)\n",
        "\n",
        "for pipe_key, pipelines in pipes_dict.items():\n",
        "    scores = []\n",
        "    preds = []\n",
        "    preds_test = []\n",
        "    print('-'*10,f'{pipe_key} pipeline training','-'*10)\n",
        "\n",
        "    for i, (param, pipe) in tqdm(enumerate(zip(params, pipelines))):\n",
        "        train_y_1d = train_y[train_y.columns[i]]\n",
        "        valid_y_1d = valid_y[valid_y.columns[i]]\n",
        "\n",
        "        search = GridSearchCV(pipe, param, scoring='neg_mean_squared_error', cv=cv, n_jobs=20, verbose=1)\n",
        "        search.fit(train_x, train_y_1d)\n",
        "        pred = search.predict(valid_x).reshape(-1)\n",
        "        pred_test = search.predict(test_x).reshape(-1)\n",
        "\n",
        "        preds.append(pred)\n",
        "        preds_test.append(pred_test)\n",
        "\n",
        "    preds_df = pd.DataFrame(preds).T\n",
        "    preds_test_df = pd.DataFrame(preds_test).T\n",
        "    print(f' nrmse : {lg_nrmse(valid_y, preds_df)}')\n",
        "\n",
        "    submit = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
        "    for idx, col in enumerate(submit.columns):\n",
        "        if col == 'ID':\n",
        "            continue\n",
        "        submit[col] = preds_test_df.iloc[:, idx - 1]\n",
        "    print('Done.')\n",
        "    submit.to_csv(f'./{pipe_key}_submit_GridSearch.csv', index=False)\n",
        "\n"
      ]
    }
  ]
}