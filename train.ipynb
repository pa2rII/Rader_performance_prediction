{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGfcJIZ3bVcPDMNKpu5JYK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssumannb/Rader_performance_prediction/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wE2IyvxhYOk",
        "outputId": "e260c6b8-aab4-41b6-e260-a22c82ee3d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WbcWuKFMhZc1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(42) # Seed 고정"
      ],
      "metadata": {
        "id": "XheWfNELhaMO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"./drive/MyDrive/Colab Notebooks/radarsensor_fault_prediction\""
      ],
      "metadata": {
        "id": "geVpXFFGheS4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(f'{PATH}/train.csv')\n",
        "train_x = train_df.filter(regex='X') # Input : X Featrue\n",
        "train_y = train_df.filter(regex='Y') # Output : Y Feature"
      ],
      "metadata": {
        "id": "jwZsydDMhe_x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2)"
      ],
      "metadata": {
        "id": "R7Tt-U-ycHne"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COL_CAT = []\n",
        "COL_CON = []"
      ],
      "metadata": {
        "id": "3sc42ScB5GCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in train_x:\n",
        "  print(col,len(train_x[col].unique()))"
      ],
      "metadata": {
        "id": "aJZSItn34mVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 전처리\n",
        "1. 결측값, 이상값 처리\n",
        "2. 변수 변환 (범주형, 연속형, 스케일링)"
      ],
      "metadata": {
        "id": "3mn_FEbX6c-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_x)\n",
        "train_x_scaled = scaler.transform(train_x)\n",
        "train_x_scaled = pd.DataFrame(train_x_scaled, columns=train_x.columns)\n",
        "\n",
        "# xy_corr(train_x_scaled,'standard scaling')\n",
        "train_x_scaled.T.head()"
      ],
      "metadata": {
        "id": "edXRPcF48klx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "8394d956-537d-4db6-a31e-a6f8790666a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6      \\\n",
              "X_01  0.801827 -0.349655  0.801827 -0.349655 -0.349655 -1.885089  1.185403   \n",
              "X_02 -0.443966 -0.443966 -0.443966 -0.443966 -0.443966 -0.443966 -0.443966   \n",
              "X_03 -0.514182 -0.708495  0.690559 -0.630770 -0.708495 -1.038828 -0.319869   \n",
              "X_04  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "X_05  1.479525 -0.528687  1.486815 -0.814793 -0.716387 -0.705453 -0.630738   \n",
              "\n",
              "         7         8         9      ...     31675     31676     31677  \\\n",
              "X_01 -0.349655 -0.733607  0.417874  ...  0.033922 -0.349655 -1.117560   \n",
              "X_02 -0.443966 -0.443966 -0.443966  ... -0.443966 -0.443966  2.252424   \n",
              "X_03 -0.727927 -0.572476 -0.339301  ...  0.807146 -0.980534 -1.272003   \n",
              "X_04  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "X_05 -0.699986 -0.639849 -0.543266  ... -0.949646 -0.517753 -0.481306   \n",
              "\n",
              "         31678     31679     31680     31681     31682     31683     31684  \n",
              "X_01 -0.733607  0.033922  0.417874  0.033922  1.185403  0.033922 -0.349655  \n",
              "X_02 -0.443966 -0.443966 -0.443966 -0.443966 -0.443966 -0.443966 -0.443966  \n",
              "X_03 -1.077690 -0.669633  0.612833  0.554539 -0.397594  0.360226 -0.805652  \n",
              "X_04  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "X_05 -0.528687 -0.643494 -0.853063 -0.734611  1.490459 -0.678118 -0.592469  \n",
              "\n",
              "[5 rows x 31685 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab75c52d-f0ef-4ec4-a529-e88cdc20de11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>31675</th>\n",
              "      <th>31676</th>\n",
              "      <th>31677</th>\n",
              "      <th>31678</th>\n",
              "      <th>31679</th>\n",
              "      <th>31680</th>\n",
              "      <th>31681</th>\n",
              "      <th>31682</th>\n",
              "      <th>31683</th>\n",
              "      <th>31684</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X_01</th>\n",
              "      <td>0.801827</td>\n",
              "      <td>-0.349655</td>\n",
              "      <td>0.801827</td>\n",
              "      <td>-0.349655</td>\n",
              "      <td>-0.349655</td>\n",
              "      <td>-1.885089</td>\n",
              "      <td>1.185403</td>\n",
              "      <td>-0.349655</td>\n",
              "      <td>-0.733607</td>\n",
              "      <td>0.417874</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033922</td>\n",
              "      <td>-0.349655</td>\n",
              "      <td>-1.117560</td>\n",
              "      <td>-0.733607</td>\n",
              "      <td>0.033922</td>\n",
              "      <td>0.417874</td>\n",
              "      <td>0.033922</td>\n",
              "      <td>1.185403</td>\n",
              "      <td>0.033922</td>\n",
              "      <td>-0.349655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_02</th>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>2.252424</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "      <td>-0.443966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_03</th>\n",
              "      <td>-0.514182</td>\n",
              "      <td>-0.708495</td>\n",
              "      <td>0.690559</td>\n",
              "      <td>-0.630770</td>\n",
              "      <td>-0.708495</td>\n",
              "      <td>-1.038828</td>\n",
              "      <td>-0.319869</td>\n",
              "      <td>-0.727927</td>\n",
              "      <td>-0.572476</td>\n",
              "      <td>-0.339301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.807146</td>\n",
              "      <td>-0.980534</td>\n",
              "      <td>-1.272003</td>\n",
              "      <td>-1.077690</td>\n",
              "      <td>-0.669633</td>\n",
              "      <td>0.612833</td>\n",
              "      <td>0.554539</td>\n",
              "      <td>-0.397594</td>\n",
              "      <td>0.360226</td>\n",
              "      <td>-0.805652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_04</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_05</th>\n",
              "      <td>1.479525</td>\n",
              "      <td>-0.528687</td>\n",
              "      <td>1.486815</td>\n",
              "      <td>-0.814793</td>\n",
              "      <td>-0.716387</td>\n",
              "      <td>-0.705453</td>\n",
              "      <td>-0.630738</td>\n",
              "      <td>-0.699986</td>\n",
              "      <td>-0.639849</td>\n",
              "      <td>-0.543266</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.949646</td>\n",
              "      <td>-0.517753</td>\n",
              "      <td>-0.481306</td>\n",
              "      <td>-0.528687</td>\n",
              "      <td>-0.643494</td>\n",
              "      <td>-0.853063</td>\n",
              "      <td>-0.734611</td>\n",
              "      <td>1.490459</td>\n",
              "      <td>-0.678118</td>\n",
              "      <td>-0.592469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31685 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab75c52d-f0ef-4ec4-a529-e88cdc20de11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab75c52d-f0ef-4ec4-a529-e88cdc20de11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab75c52d-f0ef-4ec4-a529-e88cdc20de11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Y값 정상/비정상으로 범주화"
      ],
      "metadata": {
        "id": "rfN6Ngpt6KFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_spec_info = pd.read_csv(f'{PATH}/meta/y_feature_spec_info.csv', index_col='Feature')\n",
        "y_spec_info.columns=['min_val','max_val']\n",
        "y_spec_info.head(14)"
      ],
      "metadata": {
        "id": "iLLS5jpGzXwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_class = pd.DataFrame()\n",
        "\n",
        "for col in list(train_y.columns):\n",
        "  train_y_class[col] = train_y[col].apply(lambda x: 1 if x >= y_spec_info.loc[col, 'min_val'] and x <= y_spec_info.loc[col, 'max_val'] else 0)\n",
        "\n",
        "train_y_class.head()"
      ],
      "metadata": {
        "id": "v5mUNng3z8uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_class.info()"
      ],
      "metadata": {
        "id": "GXQhOk1fO1X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_class['label'] = train_y_class.sum(axis=1)"
      ],
      "metadata": {
        "id": "XxNEgaXM1iww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_class['label'] = train_y_class['label'].apply(lambda x: True if x == 14.0 else False)"
      ],
      "metadata": {
        "id": "Os7u3UztRBCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_class['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZY9Pr7YVCQf",
        "outputId": "99daa097-9fab-4001-efc0-14757b3b507c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     28547\n",
              "False     3138\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y['label'] = train_y_class['label']"
      ],
      "metadata": {
        "id": "licufheOVved"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7EGD6QRWWHs",
        "outputId": "f02ee2f5-95fb-4e8e-8fa2-5460a6c96b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', 'Y_06', 'Y_07', 'Y_08', 'Y_09',\n",
              "       'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### X Feature and Y Feature 상관관계 체크\n",
        "* sklearn.feature_selectio.r_regression()  \n",
        ": target에 대한 각 feature의 pearson's correlation을 계산한다.  \n",
        "\n",
        "** 함수화 하여 feature engineering 결과 시각화 시 사용하기"
      ],
      "metadata": {
        "id": "vKCVGGPLeMEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import r_regression\n",
        "\n",
        "\n",
        "def xy_corr(x:pd.DataFrame, title:str):\n",
        "  correlations = []\n",
        "  Y = train_y[:]\n",
        "  for y_ in list(Y.columns):\n",
        "    correlations.append(r_regression(x, train_y[y_]))\n",
        "\n",
        "  plt.figure(figsize=(15, 5))\n",
        "  im = plt.imshow(correlations, cmap='cool', interpolation='nearest', aspect='auto')\n",
        "  plt.colorbar(im)\n",
        "  plt.xticks(np.arange(0, len(x.columns)-1), rotation=45, labels=list(x.columns))    \n",
        "  plt.yticks(np.arange(0,len(train_y.columns)-1), labels=list(train_y.columns))\n",
        "  plt.title(title)\n",
        "  plt.savefig(f'{PATH}/features/xy_corr({title}).png')\n",
        "  # plt.show()"
      ],
      "metadata": {
        "id": "2n6U_Kod6_IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xy_corr(train_x, \"original x features\")"
      ],
      "metadata": {
        "id": "UhHJoJS28E5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.info())\n",
        "print(valid_x.info())"
      ],
      "metadata": {
        "id": "FORGJUcGioKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_scaled_ = train_x_scaled.drop(['X_04', 'X_23', 'X_47', 'X_48'], axis=1)\n",
        "xy_corr(train_x_scaled_, 'drop n차검사여부')"
      ],
      "metadata": {
        "id": "S0LDeX-09-7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_range = np.arange(0.1, 1, 0.1)\n",
        "print(alpha_range)\n",
        "\n",
        "for _alpha in alpha_range:\n",
        "  MTLReg = linear_model.MultiTaskLasso(alpha=_alpha)\n",
        "  MTLReg.fit(train_x, train_y)\n",
        "  print(f'alpha({_alpha})',MTLReg.score(valid_x, valid_y))\n",
        "  print(MTLReg.coef_)\n",
        "  plt.imshow(MTLReg.coef_, cmap='cool', interpolation='nearest')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2I7d6QGehnq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 파이프라인\n",
        "\n",
        "데이터 스케일링  \n",
        "PCA  \n",
        "모델(XGBoost, RF Regressor, LigntGBM, SVR, KernelRidge)  \n",
        "*https://data-newbie.tistory.com/186"
      ],
      "metadata": {
        "id": "n8wNrnwYYZys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.linear_model import LassoCV , ElasticNetCV , RidgeCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
        "from sklearn.ensemble import RandomForestRegressor as RFR\n",
        "from sklearn.cross_decomposition import PLSRegression as  PLS\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "dC-_shw6amad"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = ShuffleSplit(n_splits=5 , test_size=0.3, random_state=42)\n",
        "pipe_linear = Pipeline([('scl', StandardScaler()),\n",
        "                        ('poly', PolynomialFeatures()),\n",
        "                        ('fit', LinearRegression())])\n",
        "pipe_lasso = Pipeline([('scl', StandardScaler()),\n",
        "                       ('poly', PolynomialFeatures()),\n",
        "                       ('fit', Lasso(random_state = 42))])\n",
        "pipe_ridge = Pipeline([('scl', StandardScaler()),\n",
        "                       ('poly', PolynomialFeatures()),\n",
        "                       ('fit', Ridge(random_state = 42))])\n",
        "pipe_pca = Pipeline([('scl', StandardScaler()),\n",
        "                     ('pca', PCA()),\n",
        "                     ('fit', Ridge(random_state = 42))])\n",
        "pipe_pls = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', PLS())])\n",
        "pipe_gbr = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', GBR())])\n",
        "pipe_rfr = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', RFR())])\n",
        "pipe_svr = Pipeline([('scl', StandardScaler()),\n",
        "                     ('fit', SVR())])\n",
        "pipe_KR = Pipeline([('scl', StandardScaler()),\n",
        "                    ('fit', KernelRidge())])\n",
        "\n",
        "pipes = [\n",
        "    pipe_linear , pipe_lasso ,  pipe_pca ,\n",
        "    pipe_ridge , pipe_pls , pipe_gbr , \n",
        "    pipe_rfr , pipe_svr , pipe_KR \n",
        "]\n",
        "pipes_label = [\n",
        "    'linear', 'lasso', 'pca', 'ridge',\n",
        "    'pls', 'gbr', 'rfr', 'svr', 'KR'\n",
        "]"
      ],
      "metadata": {
        "id": "SJL_IXObao_b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipes_dict = {}\n",
        "for i, pipe in enumerate(pipes):\n",
        "  _pipes = []\n",
        "  for _ in range(14):\n",
        "    _pipes.append(pipe)\n",
        "  \n",
        "  pipes_dict[pipes_label[i]] = _pipes\n",
        "\n",
        "pipes_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eegLXVA7YFGt",
        "outputId": "52682452-f147-408a-e0e0-9634eb5d5543"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'linear': [Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', LinearRegression())])],\n",
              " 'lasso': [Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Lasso(random_state=42))])],\n",
              " 'pca': [Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('pca', PCA()),\n",
              "                  ('fit', Ridge(random_state=42))])],\n",
              " 'ridge': [Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('poly', PolynomialFeatures()),\n",
              "                  ('fit', Ridge(random_state=42))])],\n",
              " 'pls': [Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', PLSRegression())])],\n",
              " 'gbr': [Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()),\n",
              "                  ('fit', GradientBoostingRegressor())])],\n",
              " 'rfr': [Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', RandomForestRegressor())])],\n",
              " 'svr': [Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', SVR())])],\n",
              " 'KR': [Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())]),\n",
              "  Pipeline(steps=[('scl', StandardScaler()), ('fit', KernelRidge())])]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipes_dict"
      ],
      "metadata": {
        "id": "aLRjTRa1T9dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lg_nrmse(gt, preds):\n",
        "    # 각 Y Feature별 NRMSE 총합\n",
        "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
        "    all_nrmse = []\n",
        "    for idx in range(1,15): # ignore 'ID'\n",
        "        rmse = metrics.mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
        "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
        "        all_nrmse.append(nrmse)\n",
        "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n",
        "    return score"
      ],
      "metadata": {
        "id": "hMzRbb2pXAHy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_dict = {}\n",
        "preds_dict = {}\n",
        "nrmses_dict = {}\n",
        "\n",
        "for pipe_key, pipelines in pipes_dict.items():\n",
        "  scores = []\n",
        "  preds = []\n",
        "  for i, pipe in enumerate(pipelines):\n",
        "    train_y_1d = train_y[train_y.columns[i]]\n",
        "    valid_y_1d = valid_y[valid_y.columns[i]]\n",
        "    pipe.fit(train_x, train_y_1d)\n",
        "    pred = pipe.predict(valid_x)\n",
        "    preds.append(pred)\n",
        "    scores.append(pipe.score(valid_x, valid_y_1d))\n",
        "  \n",
        "  scores_dict[pipe_key] = scores\n",
        "  preds_dict[pipe_key] = pipe_key\n",
        "#  nrmses_dict[pipe_key] = lg_nrmse(valid_y, preds)\n",
        "\n",
        "scores_dict\n",
        "preds_dict"
      ],
      "metadata": {
        "id": "Pt0kbVmMX5d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "preds = []\n",
        "nrmses = []\n",
        "\n",
        "for pipe in pipes:\n",
        "  pipe.fit(train_x, train_y)\n",
        "  preds.append(pipe.predict(valid_x))\n",
        "  scores.append(pipe.score(valid_x, valid_y))\n",
        "\n",
        "for pred in preds:\n",
        "  nrmses.append(lg_nrmse(valid_y, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "Gj81KXpoU_l5",
        "outputId": "ee8d0d4c-fac0-4a8a-dbc0-b1e3a5dd8077"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-324ba1bfc82a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     )\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (31685, 14) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### \n",
        "grid_params_linear = [{\n",
        "    \"poly__degree\" : np.arange(1,3), \n",
        "    \"fit__fit_intercept\" : [True, False], \n",
        "}]\n",
        "grid_params_lasso = [{\n",
        "    \"poly__degree\" : np.arange(1,3),\n",
        "    \"fit__tol\" : np.logspace(-5,0,10) ,\n",
        "    \"fit__alpha\" : np.logspace(-5,1,10) ,     \n",
        "                     }]\n",
        "grid_params_pca = [{\n",
        "    \"pca__n_components\" : np.arange(2,8)\n",
        "}]\n",
        "grid_params_ridge = [{\n",
        "    \"poly__degree\" : np.arange(1,3),\n",
        "    \"fit__alpha\" : np.linspace(2,5,10) ,\n",
        "    \"fit__solver\" : [ \"cholesky\",\"lsqr\",\"sparse_cg\"] ,\n",
        "    \"fit__tol\" : np.logspace(-5,0,10) ,\n",
        "                     }]\n",
        "grid_params_pls = [{\n",
        "    \"fit__n_components\" : np.arange(2,8)\n",
        "}]\n",
        "min_samples_split_range = [0.5, 0.7 , 0.9]\n",
        "\n",
        "grid_params_gbr =[{\n",
        "    \"fit__max_features\" : [\"sqrt\",\"log2\"] ,\n",
        "    \"fit__loss\" : [\"ls\",\"lad\",\"huber\",\"quantile\"] , \n",
        "    \"fit__max_depth\" : [5,6,7,8] ,\n",
        "    \"fit__min_samples_split\" : min_samples_split_range ,\n",
        "}]\n",
        "grid_params_rfr =[{\n",
        "    \"fit__max_features\" : [\"sqrt\",\"log2\"] , \n",
        "    \"fit__max_depth\" : [5,6,7,8] ,\n",
        "    \"fit__min_samples_split\" : min_samples_split_range ,\n",
        "}]\n",
        "grid_params_svr =[{\n",
        "    \"fit__kernel\" : [\"rbf\", \"linear\"] ,\n",
        "    \"fit__degree\" : [2, 3, 5] , \n",
        "    \"fit__gamma\" : np.logspace(-5,1,10) ,\n",
        "}]\n",
        "grid_params_KR =[{\n",
        "    \"fit__kernel\" : [\"rbf\",\"linear\"] , \n",
        "    \"fit__gamma\" : np.logspace(-5,1,10) ,\n",
        "}]\n",
        "pipe = [\n",
        "    pipe_linear , pipe_lasso ,  pipe_pca ,\n",
        "    pipe_ridge , pipe_pls , pipe_gbr , \n",
        "    pipe_rfr , pipe_svr , pipe_KR \n",
        "]\n",
        "\n",
        "params = [\n",
        "    grid_params_linear , grid_params_lasso , grid_params_pca,\n",
        "    grid_params_ridge , grid_params_pls , grid_params_gbr ,\n",
        "    grid_params_rfr , grid_params_svr , grid_params_KR\n",
        "]"
      ],
      "metadata": {
        "id": "Psheh32oaxZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del train_y['label']"
      ],
      "metadata": {
        "id": "V2H85Gj5boSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y0 = train_y['Y_01']\n",
        "valid_y0 = valid_y['Y_01']"
      ],
      "metadata": {
        "id": "xrpyqCWzg8Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jobs = 20\n",
        "\n",
        "grid_dict = {\n",
        "    0: 'Linear', \n",
        "    1: 'Lasso', \n",
        "    2: 'pca regression' , \n",
        "    3: 'Ridge' ,\n",
        "    4: 'PLSRegression',\n",
        "    5: \"GradientDescentRegressor\" ,\n",
        "    6: \"RandomForestRegressor\" ,\n",
        "    7: \"SupportVectorRegressor\" ,\n",
        "    8: \"Kernel RidgeRegression\"\n",
        "            }\n",
        "\n",
        "model_mse = {}\n",
        "model_r2 = {}\n",
        "model_best_params = {}\n",
        "\n",
        "for idx , (param , model) in enumerate(zip(params , pipe)) :\n",
        "    search = GridSearchCV(model, param, scoring  = \"neg_mean_squared_error\", cv=cv, n_jobs=jobs , verbose=-1)\n",
        "    search.fit(train_x, train_y0)\n",
        "    y_pred = search.predict(valid_x)\n",
        "    model_mse[grid_dict.get(idx)] = mse(valid_y0, y_pred)  \n",
        "    model_r2[grid_dict.get(idx)] = r2(valid_y0, y_pred)  \n",
        "    model_best_params[grid_dict.get(idx)] = search.best_params_\n",
        "print(\"finish\")\n",
        "\n",
        "fig ,ax = plt.subplots(figsize=(20, 10))\n",
        "sns.set(font_scale = 2)\n",
        "output = pd.DataFrame([model_r2.keys() , model_r2.values()], index = [\"algo\",\"r2\"]).T\n",
        "output.sort_values([\"r2\"], ascending= False ,inplace=True)\n",
        "ax = sns.barplot(y=\"algo\", x=\"r2\", data=output)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CQcVrI-WazZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 결과 저장"
      ],
      "metadata": {
        "id": "pCD3T_626pfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lg_nrmse(gt, preds):\n",
        "    # 각 Y Feature별 NRMSE 총합\n",
        "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
        "    all_nrmse = []\n",
        "    for idx in range(1,15): # ignore 'ID'\n",
        "        rmse = metrics.mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
        "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
        "        all_nrmse.append(nrmse)\n",
        "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n",
        "    return score"
      ],
      "metadata": {
        "id": "7TJOwv73Uq1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = pd.read_csv('./test.csv').drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "TbPmIyTvhhbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "Gu7CrXGQhh-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, col in enumerate(submit.columns):\n",
        "    if col=='ID':\n",
        "        continue\n",
        "    submit[col] = preds[:,idx-1]\n",
        "print('Done.')"
      ],
      "metadata": {
        "id": "9Zm0kBouhlZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('./submit.csv', index=False)"
      ],
      "metadata": {
        "id": "de8CciBfhmjO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}